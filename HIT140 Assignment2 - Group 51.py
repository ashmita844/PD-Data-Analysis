# -*- coding: utf-8 -*-
"""FoundationAssignment2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qgp-f5FtyPNX74pjDBr6Rb_SXSAtHrUR
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn import svm
from sklearn.metrics import accuracy_score

parkinsons_data = pd.read_csv('/content/po1_data1.csv')

#printing 5 rows of the data
parkinsons_data.head()

#number of rows and columns
parkinsons_data.shape

#getting more information about dataset
parkinsons_data.info()

#checking null values in each column
parkinsons_data.isnull().sum()

#getting some statistical measures about this data
parkinsons_data.describe()

#distribution of target variable PD_Indicator
parkinsons_data['PD indicator'].value_counts()
#1= Parkinsons Disease , 0= Healthy

#grouping data based on target variable
parkinsons_data.groupby('PD indicator').mean()

parkinsons_data.groupby('PD indicator').describe()

# finding unique values in the columns
for i in parkinsons_data.columns:
  print("*************************",i,"**************************")
  print()
  print(set(parkinsons_data[i].tolist()))
  print()

#check label imbalance
import matplotlib.pyplot as plt
import seaborn as sns
temp = parkinsons_data["PD indicator"].value_counts()
temp_parkinsons_data =pd.DataFrame({'PD indicator':temp.index,'values':temp.values})
print(sns.barplot(x= 'PD indicator',y='values',data=temp_parkinsons_data))

#checking distribution of data
#sns.pairplot(parkinsons_data)

#finding distribution of data
def distplot(col):
  sns.displot(parkinsons_data[col])
  plt.show()

for i in list(parkinsons_data.columns)[1:]:
  distplot(i)

# data is following normal distribution

def boxplots(col):
  sns.boxplot(parkinsons_data[col])
  plt.show()

for i in list(parkinsons_data.columns)[1:]:
  boxplots(i)

#finding correlations
plt.figure(figsize=(20,20))
corr=parkinsons_data.corr()
sns.heatmap(corr,annot=True)

#making changes for final data
#seperating independent and dependent variables and droping subject identifier
X= parkinsons_data.drop(["PD indicator","Subject Identifier"],axis=1)
Y= parkinsons_data["PD indicator"]

#spliting the data to traiing and testing data
X_train, X_test, Y_train, Y_test = train_test_split(X,Y,test_size=0.2, random_state=2)

print(X.shape, X_train.shape, X_test.shape)

#standardizing the data
scaler = StandardScaler()

scaler.fit(X_train)

X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)

print(X_train)

model = svm.SVC(kernel = 'linear')

#training the SVM model with the training data
model.fit (X_train, Y_train)

#accuracy score on training data
X_train_prediction = model.predict(X_train)
training_data_accuracy = accuracy_score(Y_train, X_train_prediction)

print('Accuracy Score of Training Data:', training_data_accuracy)

#accuracy score on testing data
X_test_prediction = model.predict(X_test)
testing_data_accuracy = accuracy_score(Y_test, X_test_prediction)

print('Accuracy Score of Testing Data:', testing_data_accuracy)

#Building a predictive system
input_data = (1.809,0.00014851,0.68,0.843,2.04,7.881,0.782,2.69,4.543,11.073,8.069,0.925554,0.097481,13.472,119.26,121.63,8.028,108.144,137.546,62,60,0.008211245,0.000565813,18.182,1,3.387,1)

#changing input data to a numpy array
input_data_as_numpy_array = np.asarray(input_data)

#reshape the numpy array
input_data_reshaped = input_data_as_numpy_array.reshape(1,-1)

#standardize the data
std_data = scaler.transform(input_data_reshaped)

prediction = model.predict(std_data)
print(prediction)

if (prediction[0] == 0):
  print('The person does not have Parkinsons Disease')

else:
  print('The person has Parkinsons Disease')